{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be5a390-2f35-4303-8808-f34e2c35e5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1652/1652 [00:02<00:00, 583.94 examples/s]\n",
      "Map: 100%|██████████| 415/415 [00:00<00:00, 973.95 examples/s]\n",
      "/tmp/ipykernel_1081597/447952758.py:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1035' max='1035' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1035/1035 48:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.982575</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.099816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.897466</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.726870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.614800</td>\n",
       "      <td>0.667516</td>\n",
       "      <td>0.773494</td>\n",
       "      <td>0.763321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.614800</td>\n",
       "      <td>0.640691</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.779161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.650935</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.790676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/jovyan/sku-insights/other poc/st-fake-news/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Classification Report (Integer Labels):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8723    0.8200    0.8454        50\n",
      "           1     0.7895    0.9000    0.8411        50\n",
      "           2     0.8679    0.9200    0.8932        50\n",
      "           3     0.8788    0.5800    0.6988        50\n",
      "           4     0.6200    0.6200    0.6200        50\n",
      "           5     0.7143    0.8000    0.7547        50\n",
      "           6     0.6875    0.7333    0.7097        15\n",
      "           7     0.8600    0.8600    0.8600        50\n",
      "           8     0.8679    0.9200    0.8932        50\n",
      "\n",
      "    accuracy                         0.8000       415\n",
      "   macro avg     0.7954    0.7948    0.7907       415\n",
      "weighted avg     0.8045    0.8000    0.7975       415\n",
      "\n",
      "Detailed Classification Report (String Labels):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Expert     0.8723    0.8200    0.8454        50\n",
      "        GPT4     0.7895    0.9000    0.8411        50\n",
      "      Gemini     0.8679    0.9200    0.8932        50\n",
      " Llama31405B     0.8788    0.5800    0.6988        50\n",
      "   Llama318B     0.6200    0.6200    0.6200        50\n",
      "     Mistral     0.7143    0.8000    0.7547        50\n",
      "      Novice     0.6875    0.7333    0.7097        15\n",
      "        Phi3     0.8600    0.8600    0.8600        50\n",
      "      Sonnet     0.8679    0.9200    0.8932        50\n",
      "\n",
      "    accuracy                         0.8000       415\n",
      "   macro avg     0.7954    0.7948    0.7907       415\n",
      "weighted avg     0.8045    0.8000    0.7975       415\n",
      "\n",
      "Model and tokenizer saved to ./saved_model\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BigBirdTokenizer, BigBirdForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"expandable_segments:True\"\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# Load your dataset and drop rows with missing responses\n",
    "df = pd.read_csv(\"./data/mrbench_v3_devset_train_data.csv\").dropna(subset=[\"response\"])\n",
    "\n",
    "# Convert string labels to integer indices\n",
    "# Create mapping dictionaries for encoding and later decoding\n",
    "label_list = sorted(df[\"label\"].unique())\n",
    "label_to_id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
    "\n",
    "# Replace string labels with integer labels in the DataFrame\n",
    "df[\"label\"] = df[\"label\"].map(label_to_id)\n",
    "\n",
    "# Split by conversation_id\n",
    "conversation_ids = df[\"conversation_id\"].unique()\n",
    "train_ids, test_ids = train_test_split(conversation_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = df[df[\"conversation_id\"].isin(train_ids)].reset_index(drop=True)\n",
    "test_df = df[df[\"conversation_id\"].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "train_texts = [f\"Conversation: {c}\\n\\nResponse: {r}\" for c, r in zip(train_df[\"conversation_history\"].tolist(), train_df[\"response\"].tolist())]\n",
    "test_texts = [f\"Conversation: {c}\\n\\nResponse: {r}\" for c, r in zip(test_df[\"conversation_history\"].tolist(), test_df[\"response\"].tolist())]\n",
    "\n",
    "# Now make Hugging Face Dataset objects manually\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_df[\"label\"].tolist()})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts, \"label\": test_df[\"label\"].tolist()})\n",
    "\n",
    "# Initialize tokenizer & model\n",
    "model_name = \"google/bigbird-roberta-large\"\n",
    "tokenizer = BigBirdTokenizer.from_pretrained(model_name)\n",
    "model = BigBirdForSequenceClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
    "\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=1024\n",
    "    )\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# Compute metrics function for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "    }\n",
    "\n",
    "# Training configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",  # evaluates at the end of each epoch\n",
    "    save_strategy=\"epoch\",          # saves checkpoint at each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "torch.cuda.empty_cache()\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = trainer.predict(tokenized_test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Generate detailed classification report (using integer labels)\n",
    "print(\"Detailed Classification Report (Integer Labels):\")\n",
    "print(classification_report(true_labels, preds, digits=4))\n",
    "\n",
    "# Generate classification report with target names (map back to original string labels)\n",
    "target_names = [id_to_label[i] for i in range(len(label_list))]\n",
    "print(\"Detailed Classification Report (String Labels):\")\n",
    "print(classification_report(true_labels, preds, target_names=target_names, digits=4))\n",
    "\n",
    "# --- Save the Fine-tuned Model ---\n",
    "# Before saving, update the model configuration with label mappings so that id2label and label2id\n",
    "# are stored in the saved config.json. This is necessary because categorical labels are not handled by default.\n",
    "model.config.id2label = id_to_label\n",
    "model.config.label2id = label_to_id\n",
    "\n",
    "# Save the model and tokenizer; the config will be saved automatically\n",
    "save_directory = \"./saved_model\"\n",
    "trainer.save_model(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b07fb21-3c9f-41f7-9710-0e169a8c84a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigBirdForSequenceClassification(\n",
       "  (bert): BigBirdModel(\n",
       "    (embeddings): BigBirdEmbeddings(\n",
       "      (word_embeddings): Embedding(50358, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(4096, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BigBirdEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BigBirdLayer(\n",
       "          (attention): BigBirdAttention(\n",
       "            (self): BigBirdBlockSparseAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BigBirdSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BigBirdIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): NewGELUActivation()\n",
       "          )\n",
       "          (output): BigBirdOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (classifier): BigBirdClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=9, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27543850-2928-4056-ac85-07f34a838482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 0.14, 'confidence_interval': (0.1, 0.175)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def bootstrap_ci(y_test, y_pred, calculate_metric, confidence=0.9, n_resamples=1000, sample_fraction=0.95, random_state=None):\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence interval for a metric function.\n",
    "    Parameters:\n",
    "    - y_test: array-like, true labels.\n",
    "    - y_pred: array-like, predicted labels.\n",
    "    - calculate_metric: function, computes the metric given y_test and y_pred.\n",
    "    - confidence: float, confidence level (default 0.9).\n",
    "    - n_resamples: int, number of bootstrap resamples (default 100).\n",
    "    - sample_fraction: float, fraction of data to sample in each resample (default 0.95).\n",
    "    - random_state: int or None, random seed for reproducibility.\n",
    "    Returns:\n",
    "    - (lower_bound, upper_bound): tuple of floats, confidence interval bounds.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(y_test)\n",
    "    sample_size = int(n * sample_fraction)\n",
    "    metrics = []\n",
    "    for _ in range(n_resamples):\n",
    "        indices = rng.choice(n, size=sample_size, replace=True)\n",
    "        metric = calculate_metric(np.array(y_test)[indices], np.array(y_pred)[indices])\n",
    "        metrics.append(metric)\n",
    "    alpha = (1 - confidence) / 2\n",
    "    lower = np.percentile(metrics, 100 * alpha)\n",
    "    upper = np.percentile(metrics, 100 * (1 - alpha))\n",
    "    return {\"metric\": round(calculate_metric(y_test, y_pred), 4), \"confidence_interval\": (round(lower, 4), round(upper, 4))}\n",
    "\n",
    "# def calculate_metric(y_true, y_pred):\n",
    "#     # Example: Mean Absolute Error\n",
    "#     return np.mean(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "# y_test = [1, 2, 3, 4, 5]\n",
    "# y_pred = [1.1, 1.9, 3.2, 3.8, 5.1]\n",
    "\n",
    "# print(bootstrap_ci(y_test, y_pred, calculate_metric, confidence=0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd817073-7c3d-45c6-82e7-5fa7722ce395",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 0.8, 'confidence_interval': (0.7665, 0.8325)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_metric(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "bootstrap_ci(true_labels, preds, accuracy_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62f69ff-a556-4802-9c02-938f6097caa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st-fake-news-kernel",
   "language": "python",
   "name": "st-fake-news-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
